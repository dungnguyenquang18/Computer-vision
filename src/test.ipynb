{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, root_dir, patch_size=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = sorted(os.listdir(root_dir))\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_nii(self, path):\n",
    "        return nib.load(path).get_fdata().astype(np.float32)\n",
    "\n",
    "    def random_crop(self, img, mask, size):\n",
    "        _, D, H, W = img.shape\n",
    "\n",
    "        # đảm bảo D/H/W > size\n",
    "        d = np.random.randint(0, max(1, D - size))\n",
    "        h = np.random.randint(0, max(1, H - size))\n",
    "        w = np.random.randint(0, max(1, W - size))\n",
    "\n",
    "        return (\n",
    "            img[:, d:d+size, h:h+size, w:w+size],\n",
    "            mask[d:d+size, h:h+size, w:w+size]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case = self.samples[idx]\n",
    "        folder = os.path.join(self.root_dir, case)\n",
    "\n",
    "        # flair = self.load_nii(os.path.join(folder, case + \"_flair.nii.gz\"))\n",
    "        t1 = self.load_nii(os.path.join(folder, case + \"_t1.nii.gz\"))\n",
    "        # t1ce = self.load_nii(os.path.join(folder, case + \"_t1ce.nii.gz\"))\n",
    "        # t2 = self.load_nii(os.path.join(folder, case + \"_t2.nii.gz\"))\n",
    "        mask = self.load_nii(os.path.join(folder, case + \"_seg.nii.gz\"))\n",
    "        mask[mask == 4] = 3  # convert ET label 4 → 3\n",
    "\n",
    "        # stack modal\n",
    "        image = np.stack([ t1], axis=0)\n",
    "        # image = np.stack([flair, t1, t1ce, t2], axis=0)\n",
    "        # normalize\n",
    "        image = (image - image.mean()) / (image.std() + 1e-6)\n",
    "\n",
    "        # crop patch 128³\n",
    "        image, mask = self.random_crop(image, mask, self.patch_size)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(image, dtype=torch.float32),\n",
    "            torch.tensor(mask, dtype=torch.long)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, n_channels=4, n_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = DoubleConv(n_channels, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "        self.enc4 = DoubleConv(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose3d(512, 256, 2, stride=2)\n",
    "        self.dec4 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose3d(256, 128, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(128, 64, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(128, 64)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(64, 32, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(64, 32)\n",
    "\n",
    "        self.out_conv = nn.Conv3d(32, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.enc1(x)\n",
    "        p1 = self.pool(c1)\n",
    "\n",
    "        c2 = self.enc2(p1)\n",
    "        p2 = self.pool(c2)\n",
    "\n",
    "        c3 = self.enc3(p2)\n",
    "        p3 = self.pool(c3)\n",
    "\n",
    "        c4 = self.enc4(p3)\n",
    "        p4 = self.pool(c4)\n",
    "\n",
    "        bn = self.bottleneck(p4)\n",
    "\n",
    "        u4 = self.up4(bn)\n",
    "        u4 = torch.cat([u4, c4], dim=1)\n",
    "        c5 = self.dec4(u4)\n",
    "\n",
    "        u3 = self.up3(c5)\n",
    "        u3 = torch.cat([u3, c3], dim=1)\n",
    "        c6 = self.dec3(u3)\n",
    "\n",
    "        u2 = self.up2(c6)\n",
    "        u2 = torch.cat([u2, c2], dim=1)\n",
    "        c7 = self.dec2(u2)\n",
    "\n",
    "        u1 = self.up1(c7)\n",
    "        u1 = torch.cat([u1, c1], dim=1)\n",
    "        c8 = self.dec1(u1)\n",
    "\n",
    "        return self.out_conv(c8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, eps=1e-6):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "    target_1hot = F.one_hot(target, pred.shape[1]).permute(0,4,1,2,3)\n",
    "\n",
    "    intersection = (pred * target_1hot).sum(dim=(0,2,3,4))\n",
    "    union = pred.sum(dim=(0,2,3,4)) + target_1hot.sum(dim=(0,2,3,4))\n",
    "\n",
    "    dice = (2 * intersection + eps) / (union + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def combined_loss(pred, target):\n",
    "    ce = F.cross_entropy(pred, target)\n",
    "    dl = dice_loss(pred, target)\n",
    "    return ce + dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu: 1251\n",
      "Train: 1000, Val: 125, Test: 126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "\n",
    "# Giả sử bạn đã import BratsDataset và UNet3D\n",
    "# from dataset import BratsDataset\n",
    "# from model import UNet3D\n",
    "\n",
    "# 1. Khởi tạo Dataset gốc\n",
    "full_ds = BratsDataset(\"BraTS2021_Training_Data\")\n",
    "\n",
    "# 2. Tính toán kích thước cho từng tập (Tỉ lệ 8:1:1)\n",
    "total_size = len(full_ds)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size # Lấy phần còn lại để đảm bảo tổng không bị lệch do làm tròn\n",
    "\n",
    "print(f\"Tổng số mẫu: {total_size}\")\n",
    "print(f\"Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
    "\n",
    "# 3. Thực hiện chia ngẫu nhiên (Dùng generator để cố định seed giúp kết quả lặp lại được)\n",
    "generator = torch.Generator().manual_seed(42) \n",
    "train_set, val_set, test_set = random_split(full_ds, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "# 4. Tạo DataLoader cho từng tập\n",
    "# Lưu ý: batch_size=16 cho 3D là RẤT LỚN, dễ bị tràn VRAM (OOM). \n",
    "# Với 3D UNet thường chỉ để batch_size=1 hoặc 2 tùy GPU.\n",
    "batch_size = 24\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False, num_workers=4) # Val không cần shuffle\n",
    "test_loader  = DataLoader(test_set,  batch_size=1,          shuffle=False, num_workers=4) # Test thường batch=1 để đánh giá từng ca\n",
    "\n",
    "# 5. Khởi tạo Model và Optimizer\n",
    "model = UNet3D(n_channels=1, n_classes=4).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dice(preds, targets, num_classes=4):\n",
    "    \"\"\"\n",
    "    preds: Output của model (Logits) [Batch, C, D, H, W]\n",
    "    targets: Ground Truth [Batch, D, H, W]\n",
    "    \"\"\"\n",
    "    # Chuyển logits thành xác suất rồi lấy class có xác suất cao nhất\n",
    "    preds = torch.argmax(torch.softmax(preds, dim=1), dim=1) # [B, D, H, W]\n",
    "    \n",
    "    dice_per_class = []\n",
    "    # Bỏ qua class 0 (Background) vì nó chiếm đa số, tính vào sẽ làm ảo chỉ số\n",
    "    for c in range(1, num_classes):\n",
    "        pred_c = (preds == c)\n",
    "        target_c = (targets == c)\n",
    "        \n",
    "        intersection = (pred_c & target_c).float().sum()\n",
    "        union = pred_c.float().sum() + target_c.float().sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            dice = 1.0 # Cả 2 đều không có class này => dự đoán đúng\n",
    "        else:\n",
    "            dice = (2.0 * intersection) / (union + 1e-8) # +epsilon để tránh chia cho 0\n",
    "        dice_per_class.append(dice.item())\n",
    "        \n",
    "    return sum(dice_per_class) / len(dice_per_class) # Trả về Dice trung bình của 3 class (1, 2, 3)\n",
    "\n",
    "# --- 2. Vòng lặp Training & Validation ---\n",
    "best_dice = 0.0 # Biến để theo dõi kết quả tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 139.72 GiB of which 3.09 GiB is free. Process 211501 has 123.35 GiB memory in use. Process 232482 has 13.26 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 13.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m img = img.cuda()\n\u001b[32m      6\u001b[39m mask = mask.cuda()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m loss = combined_loss(pred, mask)\n\u001b[32m     11\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mUNet3D.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     c1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     p1 = \u001b[38;5;28mself\u001b[39m.pool(c1)\n\u001b[32m     52\u001b[39m     c2 = \u001b[38;5;28mself\u001b[39m.enc2(p1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mDoubleConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:717\u001b[39m, in \u001b[36mConv3d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dungnq/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:712\u001b[39m, in \u001b[36mConv3d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    701\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv3d(\n\u001b[32m    702\u001b[39m         F.pad(\n\u001b[32m    703\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    710\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    711\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 139.72 GiB of which 3.09 GiB is free. Process 211501 has 123.35 GiB memory in use. Process 232482 has 13.26 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 13.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for img, mask in tqdm(train_loader):\n",
    "        img = img.cuda()\n",
    "        mask = mask.cuda()\n",
    "\n",
    "        pred = model(img)\n",
    "        loss = combined_loss(pred, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Loss = {sum(losses)/len(losses):.4f}\")\n",
    "    if epoch%3 == 1:\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_dices = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/20 [Valid]\")\n",
    "            for img, mask in val_pbar:\n",
    "                img = img.cuda()\n",
    "                mask = mask.cuda()\n",
    "\n",
    "                pred = model(img)\n",
    "                \n",
    "                # 1. Tính Loss\n",
    "                loss = combined_loss(pred, mask)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                # 2. Tính Dice Score (Metric đánh giá thực tế)\n",
    "                dice = calculate_dice(pred, mask, num_classes=4)\n",
    "                val_dices.append(dice)\n",
    "                \n",
    "                val_pbar.set_postfix({'val_loss': loss.item(), 'dice': dice})\n",
    "\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        avg_val_dice = sum(val_dices) / len(val_dices)\n",
    "\n",
    "        # ================= LOGGING & SAVE =================\n",
    "        print(f\"\\nEND EPOCH {epoch+1}:\")\n",
    "        # print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Valid Loss: {avg_val_loss:.4f} | Valid Dice: {avg_val_dice:.4f}\")\n",
    "\n",
    "        # Chỉ lưu model nếu Dice score cải thiện\n",
    "        if avg_val_dice > best_dice:\n",
    "            print(f\"  >>> Model Improved (Dice: {best_dice:.4f} -> {avg_val_dice:.4f}). Saving...\")\n",
    "            torch.save(model.state_dict(), \"best_unet3d_brats.pth\")\n",
    "            best_dice = avg_val_dice\n",
    "        \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
